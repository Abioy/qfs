diff --git ivy.xml ivy.xml
index 28443bd..d2c7d6a 100644
--- ivy.xml
+++ ivy.xml
@@ -30,7 +30,7 @@
     <conf name="default" extends="master,runtime"/>
     <conf name="master" description="contains the artifact but no dependencies"/>
     <conf name="runtime" description="runtime but not the artifact"
-      extends="client,server,s3-server,kfs"/>
+      extends="client,server,s3-server,kfs,qfs"/>
 
     <conf name="mandatory" description="contains the critical  dependencies"
       extends="commons-logging,log4j"/>
@@ -48,6 +48,7 @@
     <conf name="s3-server" description="dependencies for running on S3/EC2 infrastructure"
       extends="s3-client,server"/>
     <conf name="kfs" description="dependencies for KFS file system support"/>
+    <conf name="qfs" description="dependencies for QFS file system support"/>
     <conf name="ftp" description="dependencies for workign with FTP filesytems"
               extends="mandatory"/>
    <conf name="jetty" description="Jetty provides the in-VM HTTP daemon" extends="commons-logging"/>
@@ -59,7 +60,7 @@
     <conf name="javadoc" visibility="private" description="artiracts required while performing doc generation"
       extends="common,mandatory,jetty,lucene"/>
     <!--Testing pulls in everything-->
-    <conf name="test" extends="common,default,s3-server,kfs" visibility="private"
+    <conf name="test" extends="common,default,s3-server,kfs,qfs" visibility="private"
       description="the classpath needed to run tests"/>
     <conf name="releaseaudit" visibility="private"
 	description="Artifacts required for releaseaudit target"/>
diff --git src/core/core-default.xml src/core/core-default.xml
index 2800ca8..405be03 100644
--- src/core/core-default.xml
+++ src/core/core-default.xml
@@ -171,6 +171,12 @@
 </property>
 
 <property>
+  <name>fs.qfs.impl</name>
+  <value>org.apache.hadoop.fs.qfs.QuantcastFileSystem</value>
+  <description>The FileSystem for qfs: uris.</description>
+</property>
+
+<property>
   <name>fs.kfs.impl</name>
   <value>org.apache.hadoop.fs.kfs.KosmosFileSystem</value>
   <description>The FileSystem for kfs: uris.</description>
diff --git src/core/org/apache/hadoop/fs/qfs/IFSImpl.java src/core/org/apache/hadoop/fs/qfs/IFSImpl.java
new file mode 100644
index 0000000..f6d594c
--- /dev/null
+++ src/core/org/apache/hadoop/fs/qfs/IFSImpl.java
@@ -0,0 +1,67 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * We need to provide the ability to the code in fs/qfs without really
+ * having a QFS deployment.  In particular, the glue code that wraps
+ * around calls to KfsAccess object.  This is accomplished by defining a
+ * filesystem implementation interface:
+ *   -- for testing purposes, a dummy implementation of this interface
+ *      will suffice; as long as the dummy implementation is close enough
+ *      to doing what QFS does, we are good.
+ *   -- for deployment purposes with QFS, this interface is implemented by
+ *      the QfsImpl object.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.Path;
+import com.quantcast.qfs.access.KfsFileAttr;
+
+interface IFSImpl {
+  public boolean exists(String path) throws IOException;
+  public boolean isDirectory(String path) throws IOException;
+  public boolean isFile(String path) throws IOException;
+  public String[] readdir(String path) throws IOException;
+  public FileStatus[] readdirplus(Path path) throws IOException;
+  public FileStatus stat(Path path) throws IOException;
+  public KfsFileAttr fullStat(Path path) throws IOException;
+
+  public int mkdirs(String path, int mode) throws IOException;
+  public int rename(String source, String dest) throws IOException;
+
+  public int rmdir(String path) throws IOException;
+  public int remove(String path) throws IOException;
+  public long filesize(String path) throws IOException;
+  public short getReplication(String path) throws IOException;
+  public short setReplication(String path, short replication)
+           throws IOException;
+  public String[][] getDataLocation(String path, long start, long len)
+           throws IOException;
+
+  public long getModificationTime(String path) throws IOException;
+  public FSDataOutputStream create(String path, short replication,
+           int bufferSize, boolean overwrite, int mode) throws IOException;
+  public FSDataOutputStream append(String path, short replication,
+           int bufferSize) throws IOException;
+  public FSDataInputStream open(String path, int bufferSize)
+           throws IOException;
+  public void setPermission(String path, int mode) throws IOException;
+  public void setOwner(String path, String username, String groupname)
+           throws IOException;
+};
diff --git src/core/org/apache/hadoop/fs/qfs/QFSImpl.java src/core/org/apache/hadoop/fs/qfs/QFSImpl.java
new file mode 100644
index 0000000..56e0d1d
--- /dev/null
+++ src/core/org/apache/hadoop/fs/qfs/QFSImpl.java
@@ -0,0 +1,205 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * Provide the implementation of QFS which turn into calls to KfsAccess.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.permission.FsPermission;
+
+import com.quantcast.qfs.access.KfsAccess;
+import com.quantcast.qfs.access.KfsFileAttr;
+
+import java.util.ArrayList;
+
+class QFSImpl implements IFSImpl {
+  private KfsAccess kfsAccess = null;
+  private FileSystem.Statistics statistics;
+  private final long BLOCK_SIZE  = 1 << 26;
+  private final long ACCESS_TIME = 0;
+
+  public QFSImpl(String metaServerHost, int metaServerPort,
+                 FileSystem.Statistics stats) throws IOException {
+    kfsAccess = new KfsAccess(metaServerHost, metaServerPort);
+    statistics = stats;
+  }
+
+  public boolean exists(String path) throws IOException {
+    return kfsAccess.kfs_exists(path);
+  }
+
+  public boolean isDirectory(String path) throws IOException {
+    return kfsAccess.kfs_isDirectory(path);
+  }
+
+  public boolean isFile(String path) throws IOException {
+    return kfsAccess.kfs_isFile(path);
+  }
+
+  public String[] readdir(String path) throws IOException {
+    return kfsAccess.kfs_readdir(path);
+  }
+
+  public FileStatus[] readdirplus(Path path) throws IOException {
+    KfsAccess.DirectoryIterator itr = null;
+    try {
+      itr = kfsAccess.new DirectoryIterator(path.toUri().getPath());
+      final ArrayList<FileStatus> ret = new ArrayList<FileStatus>();
+      String prefix = path.toString();
+      if (! prefix.endsWith("/")) {
+        prefix += "/";
+      }
+      while (itr.next()) {
+        if (itr.filename.compareTo(".") == 0 ||
+            itr.filename.compareTo("..") == 0) {
+          continue;
+        }
+        ret.add(new FileStatus(
+          itr.isDirectory ? 0L : itr.filesize,
+          itr.isDirectory,
+          itr.isDirectory ? 1 : itr.replication,
+          itr.isDirectory ? 0 : BLOCK_SIZE,
+          itr.modificationTime,
+          ACCESS_TIME,
+          FsPermission.createImmutable((short)itr.mode),
+          itr.ownerName,
+          itr.groupName,
+          new Path(prefix + itr.filename)
+        ));
+      }
+      return ret.toArray(new FileStatus[0]);
+    } finally {
+      if (itr != null) {
+        itr.close();
+      }
+    }
+  }
+
+  public FileStatus stat(Path path) throws IOException {
+    final KfsFileAttr fa  = new KfsFileAttr();
+    final String      pn  = path.toUri().getPath();
+    kfsAccess.kfs_retToIOException(kfsAccess.kfs_stat(pn, fa), pn);
+    return new FileStatus(
+      fa.isDirectory ? 0L : fa.filesize,
+      fa.isDirectory,
+      fa.isDirectory ? 1 : fa.replication,
+      fa.isDirectory ? 0 : BLOCK_SIZE,
+      fa.modificationTime,
+      ACCESS_TIME,
+      FsPermission.createImmutable((short)fa.mode),
+      fa.ownerName,
+      fa.groupName,
+      path
+    );
+  }
+
+  public KfsFileAttr fullStat(Path path) throws IOException {
+    final KfsFileAttr fa  = new KfsFileAttr();
+    final String      pn  = path.toUri().getPath();
+    kfsAccess.kfs_retToIOException(kfsAccess.kfs_stat(pn, fa), pn);
+    return fa;
+  }
+
+  public int mkdirs(String path, int mode) throws IOException {
+    return kfsAccess.kfs_mkdirs(path, mode);
+  }
+
+  public int rename(String source, String dest) throws IOException {
+    // QFS rename does not have mv semantics.
+    // To move /a/b under /c/, you must ask for "rename /a/b /c/b"
+    String renameTarget;
+    if (kfsAccess.kfs_isDirectory(dest)) {
+      String sourceBasename = (new File(source)).getName();
+      if (dest.endsWith("/")) {
+          renameTarget = dest + sourceBasename;
+      } else {
+          renameTarget = dest + "/" + sourceBasename;
+      }
+    } else {
+      renameTarget = dest;
+    }
+    return kfsAccess.kfs_rename(source, renameTarget);
+  }
+
+  public int rmdir(String path) throws IOException {
+    return kfsAccess.kfs_rmdir(path);
+  }
+
+  public int remove(String path) throws IOException {
+    return kfsAccess.kfs_remove(path);
+  }
+
+  public long filesize(String path) throws IOException {
+    return kfsAccess.kfs_filesize(path);
+  }
+
+  public short getReplication(String path) throws IOException {
+    return kfsAccess.kfs_getReplication(path);
+  }
+
+  public short setReplication(String path, short replication)
+    throws IOException {
+    return kfsAccess.kfs_setReplication(path, replication);
+  }
+
+  public String[][] getDataLocation(String path, long start, long len)
+    throws IOException {
+    return kfsAccess.kfs_getDataLocation(path, start, len);
+  }
+
+  public long getModificationTime(String path) throws IOException {
+    return kfsAccess.kfs_getModificationTime(path);
+  }
+
+  public FSDataOutputStream create(String path, short replication,
+                                   int bufferSize, boolean overwrite,
+                                   int mode) throws IOException {
+    final boolean append = false;
+    return new FSDataOutputStream(new QFSOutputStream(
+      kfsAccess, path, replication, overwrite, append, mode), statistics);
+  }
+
+  public FSDataInputStream open(String path, int bufferSize)
+    throws IOException {
+      return new FSDataInputStream(new QFSInputStream(kfsAccess, path,
+                                                      statistics));
+  }
+
+  public FSDataOutputStream append(String path, short replication,
+                                   int bufferSize) throws IOException {
+    final boolean append    = true;
+    final boolean overwrite = false;
+    final int     mode      = 0666;
+    return new FSDataOutputStream(new QFSOutputStream(
+      kfsAccess, path, replication, overwrite, append, mode), statistics);
+  }
+
+  public void setPermission(String path, int mode) throws IOException {
+    kfsAccess.kfs_retToIOException(kfsAccess.kfs_chmod(path, mode), path);
+  }
+
+  public void setOwner(String path, String username, String groupname)
+    throws IOException {
+    kfsAccess.kfs_retToIOException(kfsAccess.kfs_chown(
+      path, username, groupname), path);
+  }
+}
diff --git src/core/org/apache/hadoop/fs/qfs/QFSInputStream.java src/core/org/apache/hadoop/fs/qfs/QFSInputStream.java
new file mode 100644
index 0000000..cbfeeec
--- /dev/null
+++ src/core/org/apache/hadoop/fs/qfs/QFSInputStream.java
@@ -0,0 +1,105 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * Implements the Hadoop FSInputStream interfaces to allow applications to read
+ * files in Quantcast File System (QFS), an extension of KFS.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+import java.nio.ByteBuffer;
+
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FSInputStream;
+
+import com.quantcast.qfs.access.KfsAccess;
+import com.quantcast.qfs.access.KfsInputChannel;
+
+class QFSInputStream extends FSInputStream {
+
+  private final KfsInputChannel kfsChannel;
+  private FileSystem.Statistics statistics;
+  private final long fsize;
+
+  public QFSInputStream(KfsAccess kfsAccess, String path,
+                        FileSystem.Statistics stats) throws IOException {
+    this.statistics = stats;
+    this.kfsChannel = kfsAccess.kfs_open(path);
+    if (kfsChannel == null) {
+      throw new IOException("QFS internal error -- null channel");
+    }
+    this.fsize = kfsAccess.kfs_filesize(path);
+  }
+
+  public long getPos() throws IOException {
+    if (kfsChannel == null) {
+      throw new IOException("File closed");
+    }
+    return kfsChannel.tell();
+  }
+
+  public synchronized int available() throws IOException {
+    return (int) (this.fsize - getPos());
+  }
+
+  public synchronized void seek(long targetPos) throws IOException {
+    kfsChannel.seek(targetPos);
+  }
+
+  public synchronized boolean seekToNewSource(long targetPos)
+    throws IOException {
+    return false;
+  }
+
+  public synchronized int read() throws IOException {
+    byte b[] = new byte[1];
+    int res = read(b, 0, 1);
+    if (res == 1) {
+      if (statistics != null) {
+        statistics.incrementBytesRead(1);
+      }
+      return ((int) (b[0] & 0xff));
+    }
+    return -1;
+  }
+
+  public synchronized int read(byte b[], int off, int len) throws IOException {
+    final int res = kfsChannel.read(ByteBuffer.wrap(b, off, len));
+    // Use -1 to signify EOF
+    if (res == 0) {
+        return -1;
+    }
+    if (statistics != null) {
+      statistics.incrementBytesRead(res);
+    }
+    return res;
+  }
+
+  public synchronized void close() throws IOException {
+    kfsChannel.close();
+  }
+
+  public boolean markSupported() {
+    return false;
+  }
+
+  public void mark(int readLimit) {
+    // Do nothing
+  }
+
+  public void reset() throws IOException {
+    throw new IOException("Mark not supported");
+  }
+}
diff --git src/core/org/apache/hadoop/fs/qfs/QFSOutputStream.java src/core/org/apache/hadoop/fs/qfs/QFSOutputStream.java
new file mode 100644
index 0000000..4113403
--- /dev/null
+++ src/core/org/apache/hadoop/fs/qfs/QFSOutputStream.java
@@ -0,0 +1,76 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * Implements the Hadoop FSOutputStream interfaces to allow applications
+ * to write to files in Quantcast File System (QFS).
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+import java.net.*;
+import java.util.*;
+import java.nio.ByteBuffer;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.util.Progressable;
+
+import com.quantcast.qfs.access.KfsAccess;
+import com.quantcast.qfs.access.KfsOutputChannel;
+
+class QFSOutputStream extends OutputStream {
+
+  private final KfsOutputChannel kfsChannel;
+
+  public QFSOutputStream(KfsAccess kfsAccess, String path, short replication,
+    boolean overwrite, boolean append, int mode) throws IOException {
+    if (append) {
+      this.kfsChannel = kfsAccess.kfs_append_ex(path, (int)replication, mode);
+    } else {
+      final long    bufferSize    = -1;
+      final long    readAheadSize = -1;
+      final boolean exclusive     = ! overwrite;
+      this.kfsChannel = kfsAccess.kfs_create_ex(
+        path, replication, exclusive, bufferSize, readAheadSize, mode);
+    }
+    if (kfsChannel == null) {
+      throw new IOException("QFS internal error -- null channel");
+    }
+  }
+
+  public long getPos() throws IOException {
+    return kfsChannel.tell();
+  }
+
+  public void write(int v) throws IOException {
+    byte[] b = new byte[1];
+    b[0] = (byte) v;
+    write(b, 0, 1);
+  }
+
+  public void write(byte b[], int off, int len) throws IOException {
+    kfsChannel.write(ByteBuffer.wrap(b, off, len));
+  }
+
+  public void flush() throws IOException {
+    kfsChannel.sync();
+  }
+
+  public synchronized void close() throws IOException {
+    flush();
+    kfsChannel.close();
+  }
+}
diff --git src/core/org/apache/hadoop/fs/qfs/QuantcastFileSystem.java src/core/org/apache/hadoop/fs/qfs/QuantcastFileSystem.java
new file mode 100644
index 0000000..08d004b
--- /dev/null
+++ src/core/org/apache/hadoop/fs/qfs/QuantcastFileSystem.java
@@ -0,0 +1,330 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * Implements the Hadoop FS interfaces to allow applications to store files in
+ * Quantcast File System (QFS). This is an extension of KFS.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+import java.net.*;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileUtil;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.ContentSummary;
+import org.apache.hadoop.fs.permission.FsPermission;
+import org.apache.hadoop.util.Progressable;
+import org.apache.hadoop.fs.BlockLocation;
+
+import com.quantcast.qfs.access.KfsFileAttr;
+
+public class QuantcastFileSystem extends FileSystem {
+
+  private FileSystem localFs;
+  private IFSImpl qfsImpl = null;
+  private URI uri;
+  private Path workingDir = new Path("/");
+
+  public QuantcastFileSystem() {
+
+  }
+
+  QuantcastFileSystem(IFSImpl fsimpl) {
+    this.qfsImpl = fsimpl;
+  }
+
+  public URI getUri() {
+    return uri;
+  }
+
+  public void initialize(URI uri, Configuration conf) throws IOException {
+    super.initialize(uri, conf);
+    try {
+      if (qfsImpl == null) {
+        if (uri.getHost() == null) {
+          qfsImpl = new QFSImpl(conf.get("fs.qfs.metaServerHost", ""),
+                                conf.getInt("fs.qfs.metaServerPort", -1),
+                                statistics);
+        } else {
+          qfsImpl = new QFSImpl(uri.getHost(), uri.getPort(), statistics);
+        }
+      }
+
+      this.localFs = FileSystem.getLocal(conf);
+      this.uri = URI.create(uri.getScheme() + "://" + uri.getAuthority());
+      this.workingDir = new Path("/user", System.getProperty("user.name")
+                                ).makeQualified(this);
+      setConf(conf);
+
+    } catch (Exception e) {
+      e.printStackTrace();
+      System.out.println("Unable to initialize QFS");
+      System.exit(-1);
+    }
+  }
+
+  public Path getWorkingDirectory() {
+    return workingDir;
+  }
+
+  public void setWorkingDirectory(Path dir) {
+    workingDir = makeAbsolute(dir);
+  }
+
+  private Path makeAbsolute(Path path) {
+    if (path.isAbsolute()) {
+      return path;
+    }
+    return new Path(workingDir, path);
+  }
+
+  public boolean mkdirs(Path path, FsPermission permission)
+    throws IOException {
+    return qfsImpl.mkdirs(makeAbsolute(path).toUri().getPath(),
+                          permission.toShort()) == 0;
+  }
+
+  @Deprecated
+  public boolean isDirectory(Path path) throws IOException {
+    Path absolute = makeAbsolute(path);
+    String srep = absolute.toUri().getPath();
+    return qfsImpl.isDirectory(srep);
+  }
+
+  @Deprecated
+  public boolean isFile(Path path) throws IOException {
+    Path absolute = makeAbsolute(path);
+    String srep = absolute.toUri().getPath();
+    return qfsImpl.isFile(srep);
+  }
+
+  public FileStatus[] listStatus(Path path) throws IOException {
+    final Path absolute = makeAbsolute(path);
+    final FileStatus fs = qfsImpl.stat(absolute);
+    return fs.isDir() ?
+      qfsImpl.readdirplus(absolute) :
+      new FileStatus[] { fs };
+  }
+
+  public FileStatus getFileStatus(Path path) throws IOException {
+    return qfsImpl.stat(makeAbsolute(path));
+  }
+
+  public FSDataOutputStream append(Path path, int bufferSize,
+                                   Progressable progress) throws IOException {
+    return qfsImpl.append(
+          makeAbsolute(path).toUri().getPath(), (short)-1, bufferSize);
+  }
+
+  public FSDataOutputStream create(Path file, FsPermission permission,
+                                   boolean overwrite, int bufferSize,
+                                   short replication, long blockSize,
+                                   Progressable progress)
+    throws IOException {
+    Path parent = file.getParent();
+    if (parent != null && !mkdirs(parent)) {
+      throw new IOException("Mkdirs failed to create " + parent);
+    }
+    return qfsImpl.create(makeAbsolute(file).toUri().getPath(),
+      replication, bufferSize, overwrite, permission.toShort());
+  }
+
+  public FSDataInputStream open(Path path, int bufferSize) throws IOException {
+    return qfsImpl.open(makeAbsolute(path).toUri().getPath(), bufferSize);
+  }
+
+  public boolean rename(Path src, Path dst) throws IOException {
+    Path absoluteS = makeAbsolute(src);
+    String srepS = absoluteS.toUri().getPath();
+    Path absoluteD = makeAbsolute(dst);
+    String srepD = absoluteD.toUri().getPath();
+
+    return qfsImpl.rename(srepS, srepD) == 0;
+  }
+
+  // recursively delete the directory and its contents
+  public boolean delete(Path path, boolean recursive) throws IOException {
+    Path absolute = makeAbsolute(path);
+    String srep = absolute.toUri().getPath();
+    if (qfsImpl.isFile(srep))
+      return qfsImpl.remove(srep) == 0;
+
+    FileStatus[] dirEntries = listStatus(absolute);
+    if ((!recursive) && (dirEntries != null) && (dirEntries.length != 0)) {
+      throw new IOException("Directory " + path.toString() + " is not empty.");
+    }
+    if (dirEntries != null) {
+      for (int i = 0; i < dirEntries.length; i++) {
+        delete(new Path(absolute, dirEntries[i].getPath()), recursive);
+      }
+    }
+    return qfsImpl.rmdir(srep) == 0;
+  }
+
+  @Deprecated
+  public boolean delete(Path path) throws IOException {
+    return delete(path, true);
+  }
+
+  public short getDefaultReplication() {
+    return 3;
+  }
+
+  public boolean setReplication(Path path, short replication)
+    throws IOException {
+
+    Path absolute = makeAbsolute(path);
+    String srep = absolute.toUri().getPath();
+
+    int res = qfsImpl.setReplication(srep, replication);
+    return res >= 0;
+  }
+
+  // 64MB is the QFS block size
+  public long getDefaultBlockSize() {
+    return 1 << 26;
+  }
+
+  /**
+   * Return null if the file doesn't exist; otherwise, get the
+   * locations of the various chunks of the file file from QFS.
+   */
+  @Override
+  public BlockLocation[] getFileBlockLocations(FileStatus file,
+    long start, long len) throws IOException {
+
+    if (file == null) {
+      return null;
+    }
+    String srep = makeAbsolute(file.getPath()).toUri().getPath();
+    String[][] hints = qfsImpl.getDataLocation(srep, start, len);
+    if (hints == null) {
+      return null;
+    }
+    BlockLocation[] result = new BlockLocation[hints.length];
+    long blockSize = getDefaultBlockSize();
+    long length = len;
+    long blockStart = start;
+    for(int i=0; i < result.length; ++i) {
+      result[i] = new BlockLocation(
+                      null,
+                      hints[i],
+                      blockStart,
+                      length < blockSize ? length : blockSize);
+      blockStart += blockSize;
+      length -= blockSize;
+    }
+    return result;
+  }
+
+  public void copyFromLocalFile(boolean delSrc, Path src, Path dst)
+    throws IOException {
+    FileUtil.copy(localFs, src, this, dst, delSrc, getConf());
+  }
+
+  public void copyToLocalFile(boolean delSrc, Path src, Path dst)
+    throws IOException {
+    FileUtil.copy(this, src, localFs, dst, delSrc, getConf());
+  }
+
+  public Path startLocalOutput(Path fsOutputFile, Path tmpLocalFile)
+    throws IOException {
+    return tmpLocalFile;
+  }
+
+  public void completeLocalOutput(Path fsOutputFile, Path tmpLocalFile)
+    throws IOException {
+    moveFromLocalFile(tmpLocalFile, fsOutputFile);
+  }
+
+  public void setPermission(Path path, FsPermission permission)
+    throws IOException {
+    qfsImpl.setPermission(makeAbsolute(path).toUri().getPath(),
+                          permission.toShort());
+  }
+
+  public void setOwner(Path path, String username, String groupname)
+    throws IOException {
+    qfsImpl.setOwner(makeAbsolute(path).toUri().getPath(),
+      username, groupname);
+  }
+
+  // The following is to get du and dus working without implementing file
+  // and directory counts on in the meta server.
+  private class ContentSummaryProxy extends ContentSummary
+  {
+    private ContentSummary cs;
+    private final Path path;
+
+    private ContentSummaryProxy(Path path, long len) {
+      super(len, -1, -1);
+      this.path = path;
+    }
+
+    private ContentSummary get() {
+      if (cs == null) {
+        try {
+          cs = getContentSummarySuper(path);
+        } catch (IOException ex) {
+          cs = this;
+        }
+      }
+      return cs;
+    }
+
+    public long getDirectoryCount() {
+      return get().getDirectoryCount();
+    }
+
+    public long getFileCount() {
+      return get().getFileCount();
+    }
+
+    public void write(DataOutput out) throws IOException {
+      get().write(out);
+    }
+
+    public String toString(boolean qOption) {
+      return get().toString(qOption);
+    }
+  }
+
+  private ContentSummary getContentSummarySuper(Path path) throws IOException {
+    return super.getContentSummary(path);
+  }
+
+  public ContentSummary getContentSummary(Path path) throws IOException {
+    // since QFS stores sizes at each level of the dir tree, we can
+    // just stat the dir.
+    final Path absolute = makeAbsolute(path);
+    final KfsFileAttr stat = qfsImpl.fullStat(absolute);
+    if (stat.isDirectory) {
+      final long len = stat.filesize;
+      if (len < 0) {
+        return getContentSummarySuper(absolute);
+      }
+      if (stat.dirCount < 0) {
+        return new ContentSummaryProxy(absolute, len);
+      }
+      return new ContentSummary(len, stat.fileCount, stat.dirCount + 1);
+    }
+    return new ContentSummary(stat.filesize, 1, 0);
+  }
+}
diff --git src/core/org/apache/hadoop/fs/qfs/package.html src/core/org/apache/hadoop/fs/qfs/package.html
new file mode 100644
index 0000000..ce40d9d
--- /dev/null
+++ src/core/org/apache/hadoop/fs/qfs/package.html
@@ -0,0 +1,98 @@
+<html>
+
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+
+<head></head>
+<body>
+<h1>A client for the Quantcast filesystem (QFS)</h1>
+
+<h3>Introduction</h3>
+
+This pages describes how to use Quantcast Filesystem
+(<a href="https://github.com/quantcast/qfs"> QFS </a>) as a backing
+store with Hadoop. QFS is derived from the Kosmos File System (KFS).
+This page assumes that you have downloaded the QFS software and
+installed necessary binaries as outlined in the QFS documentation.
+
+<h3>Steps</h3>
+
+        <ul>
+          <li>In the Hadoop conf directory edit core-site.xml,
+          add the following:
+            <pre>
+&lt;property&gt;
+  &lt;name&gt;fs.qfs.impl&lt;/name&gt;
+  &lt;value&gt;org.apache.hadoop.fs.qfs.QuantcastFileSystem&lt;/value&gt;
+  &lt;description&gt;The FileSystem for qfs: uris.&lt;/description&gt;
+&lt;/property&gt;
+            </pre>
+
+          <li>In the Hadoop conf directory edit core-site.xml,
+          adding the following (with appropriate values for
+          &lt;server&gt; and &lt;port&gt;):
+            <pre>
+&lt;property&gt;
+  &lt;name&gt;fs.default.name&lt;/name&gt;
+  &lt;value&gt;qfs://&lt;server:port&gt;&lt;/value&gt;
+&lt;/property&gt;
+
+&lt;property&gt;
+  &lt;name&gt;fs.qfs.metaServerHost&lt;/name&gt;
+  &lt;value&gt;&lt;server&gt;&lt;/value&gt;
+  &lt;description&gt;The location of the QFS meta server.&lt;/description&gt;
+&lt;/property&gt;
+
+&lt;property&gt;
+  &lt;name&gt;fs.qfs.metaServerPort&lt;/name&gt;
+  &lt;value&gt;&lt;port&gt;&lt;/value&gt;
+  &lt;description&gt;The location of the meta server's port.&lt;/description&gt;
+&lt;/property&gt;
+
+</pre>
+          </li>
+
+          <li>Copy QFS's <i> qfs-&lt;version&gt;.jar </i> to Hadoop's lib directory.  This step
+          enables Hadoop's to load the QFS specific modules.  Note
+          that, qfs-&lt;version&gt;.jar was built when you compiled QFS source
+          code.  This jar file contains code that calls QFS's client
+          library code via JNI; the native code is in QFS's <i>
+          libqfs_client.so </i> library.
+          </li>
+
+          <li> When the Hadoop map/reduce trackers start up, those
+processes (on local as well as remote nodes) will now need to load
+QFS's <i> libqfs_client.so </i> library.  To simplify this process, it is advisable to
+store libqfs_client.so in an NFS accessible directory (similar to where
+Hadoop binaries/scripts are stored); then, modify Hadoop's
+conf/hadoop-env.sh adding the following line and providing suitable
+value for &lt;path&gt;:
+<pre>
+export LD_LIBRARY_PATH=&lt;path&gt;
+</pre>
+
+
+          <li>Start only the map/reduce trackers
+          <br />
+          example: execute Hadoop's bin/start-mapred.sh</li>
+        </ul>
+<br/>
+
+If the map/reduce job trackers start up, all file-I/O is done to QFS.
+
+</body>
+</html>
diff --git src/test/commit-tests src/test/commit-tests
index 45256d9..ebdf09e 100644
--- src/test/commit-tests
+++ src/test/commit-tests
@@ -37,6 +37,7 @@
 **/TestIPC.java
 **/TestIPCServerResponder.java
 **/TestKosmosFileSystem.java
+**/TestQuantcastFileSystem.java
 **/TestLocalDirAllocator.java
 **/TestLocalFileSystem.java
 **/TestLocalFileSystemPermission.java
diff --git src/test/org/apache/hadoop/fs/qfs/QFSEmulationImpl.java src/test/org/apache/hadoop/fs/qfs/QFSEmulationImpl.java
new file mode 100644
index 0000000..c1fb8cc
--- /dev/null
+++ src/test/org/apache/hadoop/fs/qfs/QFSEmulationImpl.java
@@ -0,0 +1,185 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * We need to provide the ability to the code in fs/kfs without really
+ * having a KFS deployment.  For this purpose, use the LocalFileSystem
+ * as a way to "emulate" KFS.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+
+import org.apache.hadoop.conf.Configuration;
+
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileUtil;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.BlockLocation;
+import org.apache.hadoop.fs.permission.FsPermission;
+import com.quantcast.qfs.access.KfsFileAttr;
+
+
+public class QFSEmulationImpl implements IFSImpl {
+  FileSystem localFS;
+
+  public QFSEmulationImpl(Configuration conf) throws IOException {
+    localFS = FileSystem.getLocal(conf);
+  }
+
+  public boolean exists(String path) throws IOException {
+    return localFS.exists(new Path(path));
+  }
+
+  public boolean isDirectory(String path) throws IOException {
+    return localFS.isDirectory(new Path(path));
+  }
+
+  public boolean isFile(String path) throws IOException {
+    return localFS.isFile(new Path(path));
+  }
+
+  public String[] readdir(String path) throws IOException {
+    FileStatus[] p = localFS.listStatus(new Path(path));
+    String[] entries = null;
+
+    if (p == null) {
+      return null;
+    }
+
+    entries = new String[p.length];
+    for (int i = 0; i < p.length; i++) {
+      entries[i] = p[i].getPath().toString();
+    }
+    return entries;
+  }
+
+  public FileStatus[] readdirplus(Path path) throws IOException {
+    return localFS.listStatus(path);
+  }
+
+  public FileStatus stat(Path path) throws IOException {
+    return localFS.getFileStatus(path);
+  }
+
+  public KfsFileAttr fullStat(Path path) throws IOException {
+    FileStatus fs = localFS.getFileStatus(path);
+    KfsFileAttr fa = new KfsFileAttr();
+    fa.filename = fs.getPath().toString();
+    fa.isDirectory = fs.isDir();
+    fa.filesize = fs.getLen();
+    fa.replication = fs.getReplication();
+    fa.modificationTime = fs.getModificationTime();
+    return fa;
+  }
+
+  public int mkdirs(String path, int mode) throws IOException {
+    if (localFS.mkdirs(new Path(path))) {
+      return 0;
+    }
+    return -1;
+  }
+
+  public int rename(String source, String dest) throws IOException {
+    if (localFS.rename(new Path(source), new Path(dest))) {
+      return 0;
+    }
+    return -1;
+  }
+
+  public int rmdir(String path) throws IOException {
+    if (isDirectory(path)) {
+      // the directory better be empty
+      String[] dirEntries = readdir(path);
+      if ((dirEntries.length <= 2) && (localFS.delete(new Path(path), true))) {
+        return 0;
+      }
+    }
+    return -1;
+  }
+
+  public int remove(String path) throws IOException {
+    if (isFile(path) && (localFS.delete(new Path(path), true))) {
+      return 0;
+    }
+    return -1;
+  }
+
+  public long filesize(String path) throws IOException {
+    return localFS.getLength(new Path(path));
+  }
+
+  public short getReplication(String path) throws IOException {
+    return 1;
+  }
+
+  public short setReplication(String path, short replication)
+    throws IOException {
+    return 1;
+  }
+
+  public String[][] getDataLocation(String path, long start, long len)
+    throws IOException {
+    BlockLocation[] blkLocations = localFS.getFileBlockLocations(
+      localFS.getFileStatus(new Path(path)), start, len);
+    if ((blkLocations == null) || (blkLocations.length == 0)) {
+      return new String[0][];
+    }
+    int blkCount = blkLocations.length;
+    String[][]hints = new String[blkCount][];
+    for (int i=0; i < blkCount ; i++) {
+      String[] hosts = blkLocations[i].getHosts();
+      hints[i] = new String[hosts.length];
+      hints[i] = hosts;
+    }
+    return hints;
+  }
+
+  public long getModificationTime(String path) throws IOException {
+    FileStatus s = localFS.getFileStatus(new Path(path));
+    if (s == null) {
+      return 0;
+    }
+    return s.getModificationTime();
+  }
+
+  public FSDataOutputStream create(String path, short replication,
+    int bufferSize, boolean overwrite, int mode) throws IOException {
+    // besides path/overwrite, the other args don't matter for
+    // testing purposes.
+    return localFS.create(new Path(path));
+  }
+
+  public FSDataInputStream open(String path, int bufferSize)
+    throws IOException {
+    return localFS.open(new Path(path));
+  }
+
+  public FSDataOutputStream append(String path, short replication,
+    int bufferSize) throws IOException {
+    return localFS.create(new Path(path));
+  }
+
+  public void setPermission(String path, int mode) throws IOException {
+    localFS.setPermission(new Path(path), new FsPermission((short)mode));
+  }
+
+  public void setOwner(String path, String username, String groupname)
+    throws IOException {
+    localFS.setOwner(new Path(path), username, groupname);
+  }
+}
diff --git src/test/org/apache/hadoop/fs/qfs/TestQuantcastFileSystem.java src/test/org/apache/hadoop/fs/qfs/TestQuantcastFileSystem.java
new file mode 100644
index 0000000..a3c4ce6
--- /dev/null
+++ src/test/org/apache/hadoop/fs/qfs/TestQuantcastFileSystem.java
@@ -0,0 +1,179 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * Unit tests for testing the KosmosFileSystem API implementation.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+import java.net.*;
+
+import junit.framework.TestCase;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileUtil;
+import org.apache.hadoop.fs.Path;
+
+import org.apache.hadoop.fs.qfs.QuantcastFileSystem;
+
+public class TestQuantcastFileSystem extends TestCase {
+
+  QuantcastFileSystem quantcastFileSystem;
+  QFSEmulationImpl qfsEmul;
+  Path baseDir;
+
+  @Override
+  protected void setUp() throws IOException {
+    Configuration conf = new Configuration();
+
+    qfsEmul = new QFSEmulationImpl(conf);
+    quantcastFileSystem = new QuantcastFileSystem(qfsEmul);
+    // a dummy URI; we are not connecting to any setup here
+    quantcastFileSystem.initialize(URI.create("qfs:///"), conf);
+    baseDir = new Path(System.getProperty("test.build.data", "/tmp" ) +
+                                          "/qfs-test");
+  }
+
+  @Override
+  protected void tearDown() throws Exception {
+
+  }
+
+  // @Test
+  // Check all the directory API's in QFS
+  public void testDirs() throws Exception {
+    Path subDir1 = new Path("dir.1");
+
+    // make the dir
+    quantcastFileSystem.mkdirs(baseDir);
+    assertTrue(quantcastFileSystem.isDirectory(baseDir));
+    quantcastFileSystem.setWorkingDirectory(baseDir);
+
+    quantcastFileSystem.mkdirs(subDir1);
+    assertTrue(quantcastFileSystem.isDirectory(subDir1));
+
+    assertFalse(quantcastFileSystem.exists(new Path("test1")));
+    assertFalse(quantcastFileSystem.isDirectory(new Path("test/dir.2")));
+
+    FileStatus[] p = quantcastFileSystem.listStatus(baseDir);
+    assertEquals(p.length, 1);
+
+    quantcastFileSystem.delete(baseDir, true);
+    assertFalse(quantcastFileSystem.exists(baseDir));
+  }
+
+  // @Test
+  // Check the file API's
+  public void testFiles() throws Exception {
+    Path subDir1 = new Path("dir.1");
+    Path file1 = new Path("dir.1/foo.1");
+    Path file2 = new Path("dir.1/foo.2");
+
+    quantcastFileSystem.mkdirs(baseDir);
+    assertTrue(quantcastFileSystem.isDirectory(baseDir));
+    quantcastFileSystem.setWorkingDirectory(baseDir);
+
+    quantcastFileSystem.mkdirs(subDir1);
+
+    FSDataOutputStream s1 = quantcastFileSystem.create(
+      file1, true, 4096, (short) 1, (long) 4096, null);
+    FSDataOutputStream s2 = quantcastFileSystem.create(
+      file2, true, 4096, (short) 1, (long) 4096, null);
+
+    s1.close();
+    s2.close();
+
+    FileStatus[] p = quantcastFileSystem.listStatus(subDir1);
+    assertEquals(p.length, 2);
+
+    quantcastFileSystem.delete(file1, true);
+    p = quantcastFileSystem.listStatus(subDir1);
+    assertEquals(p.length, 1);
+
+    quantcastFileSystem.delete(file2, true);
+    p = quantcastFileSystem.listStatus(subDir1);
+    assertEquals(p.length, 0);
+
+    quantcastFileSystem.delete(baseDir, true);
+    assertFalse(quantcastFileSystem.exists(baseDir));
+  }
+
+  // @Test
+  // Check file/read write
+  public void testFileIO() throws Exception {
+    Path subDir1 = new Path("dir.1");
+    Path file1 = new Path("dir.1/foo.1");
+
+    quantcastFileSystem.mkdirs(baseDir);
+    assertTrue(quantcastFileSystem.isDirectory(baseDir));
+    quantcastFileSystem.setWorkingDirectory(baseDir);
+
+    quantcastFileSystem.mkdirs(subDir1);
+
+    FSDataOutputStream s1 = quantcastFileSystem.create(
+      file1, true, 4096, (short) 1, (long) 4096, null);
+
+    int bufsz = 4096;
+    byte[] data = new byte[bufsz];
+
+    for (int i = 0; i < data.length; i++)
+        data[i] = (byte) (i % 16);
+
+    // write 4 bytes and read them back; read API should return a byte per call
+    s1.write(32);
+    s1.write(32);
+    s1.write(32);
+    s1.write(32);
+    // write some data
+    s1.write(data, 0, data.length);
+    // flush out the changes
+    s1.close();
+
+    // Read the stuff back and verify it is correct
+    FSDataInputStream s2 = quantcastFileSystem.open(file1, 4096);
+    int v;
+
+    v = s2.read();
+    assertEquals(v, 32);
+    v = s2.read();
+    assertEquals(v, 32);
+    v = s2.read();
+    assertEquals(v, 32);
+    v = s2.read();
+    assertEquals(v, 32);
+
+    assertEquals(s2.available(), data.length);
+
+    byte[] buf = new byte[bufsz];
+    s2.read(buf, 0, buf.length);
+    for (int i = 0; i < data.length; i++)
+        assertEquals(data[i], buf[i]);
+
+    assertEquals(s2.available(), 0);
+
+    s2.close();
+
+    quantcastFileSystem.delete(file1, true);
+    assertFalse(quantcastFileSystem.exists(file1));
+    quantcastFileSystem.delete(subDir1, true);
+    assertFalse(quantcastFileSystem.exists(subDir1));
+    quantcastFileSystem.delete(baseDir, true);
+    assertFalse(quantcastFileSystem.exists(baseDir));
+  }
+}
