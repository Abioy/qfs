diff --git a/ivy.xml b/ivy.xml
index ca87608..6b34081 100644
--- a/ivy.xml
+++ b/ivy.xml
@@ -30,7 +30,7 @@
     <conf name="default" extends="master,runtime"/>
     <conf name="master" description="contains the artifact but no dependencies"/>
     <conf name="runtime" description="runtime but not the artifact"
-      extends="client,server,s3-server,kfs"/>
+      extends="client,server,s3-server,kfs,qfs"/>
 
     <conf name="mandatory" description="contains the critical  dependencies"
       extends="commons-logging,log4j"/>
@@ -48,6 +48,7 @@
     <conf name="s3-server" description="dependencies for running on S3/EC2 infrastructure"
       extends="s3-client,server"/>
     <conf name="kfs" description="dependencies for KFS file system support"/>
+    <conf name="qfs" description="dependencies for QFS file system support"/>
     <conf name="ftp" description="dependencies for workign with FTP filesytems"
               extends="mandatory"/>
    <conf name="jetty" description="Jetty provides the in-VM HTTP daemon" extends="commons-logging"/>
@@ -59,7 +60,7 @@
     <conf name="javadoc" visibility="private" description="artiracts required while performing doc generation"
       extends="common,mandatory,jetty,lucene"/>
     <!--Testing pulls in everything-->
-    <conf name="test" extends="common,default,s3-server,kfs" visibility="private"
+    <conf name="test" extends="common,default,s3-server,kfs,qfs" visibility="private"
       description="the classpath needed to run tests"/>
     <conf name="releaseaudit" visibility="private"
 	description="Artifacts required for releaseaudit target"/>
diff --git a/src/core/core-default.xml b/src/core/core-default.xml
index 2800ca8..028b7ab 100644
--- a/src/core/core-default.xml
+++ b/src/core/core-default.xml
@@ -177,6 +177,12 @@
 </property>
 
 <property>
+  <name>fs.qfs.impl</name>
+  <value>org.apache.hadoop.fs.qfs.QuantcastFileSystem</value>
+  <description>The FileSystem for qfs: uris.</description>
+</property>
+
+<property>
   <name>fs.hftp.impl</name>
   <value>org.apache.hadoop.hdfs.HftpFileSystem</value>
 </property>
diff --git a/src/core/org/apache/hadoop/fs/qfs/IFSImpl.java b/src/core/org/apache/hadoop/fs/qfs/IFSImpl.java
new file mode 100644
index 0000000..fa0b611
--- /dev/null
+++ b/src/core/org/apache/hadoop/fs/qfs/IFSImpl.java
@@ -0,0 +1,63 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * @author: Sriram Rao (Kosmix Corp.)
+ *
+ * We need to provide the ability to the code in fs/qfs without really
+ * having a QFS deployment.  In particular, the glue code that wraps
+ * around calls to KfsAccess object.  This is accomplished by defining a
+ * filesystem implementation interface:
+ *   -- for testing purposes, a dummy implementation of this interface
+ *      will suffice; as long as the dummy implementation is close enough
+ *      to doing what QFS does, we are good.
+ *   -- for deployment purposes with QFS, this interface is implemented by
+ *      the QfsImpl object.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.Path;
+import com.quantcast.qfs.access.KfsFileAttr;
+
+interface IFSImpl {
+    public boolean exists(String path) throws IOException;
+    public boolean isDirectory(String path) throws IOException;
+    public boolean isFile(String path) throws IOException;
+    public String[] readdir(String path) throws IOException;
+    public FileStatus[] readdirplus(Path path) throws IOException;
+    public FileStatus stat(Path path) throws IOException;
+    public KfsFileAttr fullStat(Path path) throws IOException;
+
+    public int mkdirs(String path, int mode) throws IOException;
+    public int rename(String source, String dest) throws IOException;
+
+    public int rmdir(String path) throws IOException;
+    public int remove(String path) throws IOException;
+    public long filesize(String path) throws IOException;
+    public short getReplication(String path) throws IOException;
+    public short setReplication(String path, short replication) throws IOException;
+    public String[][] getDataLocation(String path, long start, long len) throws IOException;
+
+    public long getModificationTime(String path) throws IOException;
+    public FSDataOutputStream create(String path, short replication, int bufferSize, boolean overwrite, int mode) throws IOException;
+    public FSDataOutputStream append(String path, short replication, int bufferSize) throws IOException;
+    public FSDataInputStream open(String path, int bufferSize) throws IOException;
+    public void setPermission(String path, int mode) throws IOException;
+    public void setOwner(String path, String username, String groupname) throws IOException;
+};
diff --git a/src/core/org/apache/hadoop/fs/qfs/QFSImpl.java b/src/core/org/apache/hadoop/fs/qfs/QFSImpl.java
new file mode 100644
index 0000000..050e554
--- /dev/null
+++ b/src/core/org/apache/hadoop/fs/qfs/QFSImpl.java
@@ -0,0 +1,202 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * @author: Sriram Rao (Kosmix Corp.)
+ *
+ * Provide the implementation of QFS which turn into calls to KfsAccess.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.permission.FsPermission;
+
+import com.quantcast.qfs.access.KfsAccess;
+import com.quantcast.qfs.access.KfsFileAttr;
+
+import java.util.ArrayList;
+
+class QFSImpl implements IFSImpl {
+    private KfsAccess kfsAccess = null;
+    private FileSystem.Statistics statistics;
+    private final long BLOCK_SIZE  = 1 << 26;
+    private final long ACCESS_TIME = 0;
+
+    public QFSImpl(String metaServerHost, int metaServerPort,
+                   FileSystem.Statistics stats) throws IOException {
+        kfsAccess = new KfsAccess(metaServerHost, metaServerPort);
+        statistics = stats;
+    }
+
+    public boolean exists(String path) throws IOException {
+        return kfsAccess.kfs_exists(path);
+    }
+
+    public boolean isDirectory(String path) throws IOException {
+        return kfsAccess.kfs_isDirectory(path);
+    }
+
+    public boolean isFile(String path) throws IOException {
+        return kfsAccess.kfs_isFile(path);
+    }
+
+    public String[] readdir(String path) throws IOException {
+        return kfsAccess.kfs_readdir(path);
+    }
+
+    public FileStatus[] readdirplus(Path path) throws IOException {
+        KfsAccess.DirectoryIterator itr = null;
+        try {
+            itr = kfsAccess.new DirectoryIterator(path.toUri().getPath());
+            final ArrayList<FileStatus> ret = new ArrayList<FileStatus>();
+            String prefix = path.toString();
+            if (! prefix.endsWith("/")) {
+                prefix += "/";
+            }
+            while (itr.next()) {
+                if (itr.filename.compareTo(".") == 0 ||
+                        itr.filename.compareTo("..") == 0) {
+                    continue;
+                }
+                ret.add(new FileStatus(
+                    itr.isDirectory ? 0L : itr.filesize,
+                    itr.isDirectory,
+                    itr.isDirectory ? 1 : itr.replication,
+                    itr.isDirectory ? 0 : BLOCK_SIZE,
+                    itr.modificationTime,
+                    ACCESS_TIME,
+                    FsPermission.createImmutable((short)itr.mode),
+                    itr.ownerName,
+                    itr.groupName,
+                    new Path(prefix + itr.filename)
+                ));
+            }
+            return ret.toArray(new FileStatus[0]);
+        } finally {
+            if (itr != null) {
+                itr.close();
+            }
+        }
+    }
+
+    public FileStatus stat(Path path) throws IOException {
+        final KfsFileAttr fa  = new KfsFileAttr();
+        final String      pn  = path.toUri().getPath();
+        kfsAccess.kfs_retToIOException(kfsAccess.kfs_stat(pn, fa), pn);
+        return new FileStatus(
+            fa.isDirectory ? 0L : fa.filesize,
+            fa.isDirectory,
+            fa.isDirectory ? 1 : fa.replication,
+            fa.isDirectory ? 0 : BLOCK_SIZE,
+            fa.modificationTime,
+            ACCESS_TIME,
+            FsPermission.createImmutable((short)fa.mode),
+            fa.ownerName,
+            fa.groupName,
+            path
+        );
+    }
+
+    public KfsFileAttr fullStat(Path path) throws IOException {
+        final KfsFileAttr fa  = new KfsFileAttr();
+        final String      pn  = path.toUri().getPath();
+        kfsAccess.kfs_retToIOException(kfsAccess.kfs_stat(pn, fa), pn);
+        return fa;
+    }
+
+    public int mkdirs(String path, int mode) throws IOException {
+        return kfsAccess.kfs_mkdirs(path, mode);
+    }
+
+    public int rename(String source, String dest) throws IOException {
+        // QFS rename does not have mv semantics.
+        // To move /a/b under /c/, you must ask for "rename /a/b /c/b"
+        String renameTarget;
+        if (kfsAccess.kfs_isDirectory(dest)) {
+            String sourceBasename = (new File(source)).getName();
+            if (dest.endsWith("/")) {
+                renameTarget = dest + sourceBasename;
+            } else {
+                renameTarget = dest + "/" + sourceBasename;
+            }
+        } else {
+            renameTarget = dest;
+        }
+        return kfsAccess.kfs_rename(source, renameTarget);
+    }
+
+    public int rmdir(String path) throws IOException {
+        return kfsAccess.kfs_rmdir(path);
+    }
+
+    public int remove(String path) throws IOException {
+        return kfsAccess.kfs_remove(path);
+    }
+
+    public long filesize(String path) throws IOException {
+        return kfsAccess.kfs_filesize(path);
+    }
+
+    public short getReplication(String path) throws IOException {
+        return kfsAccess.kfs_getReplication(path);
+    }
+
+    public short setReplication(String path, short replication) throws IOException {
+        return kfsAccess.kfs_setReplication(path, replication);
+    }
+
+    public String[][] getDataLocation(String path, long start, long len) throws IOException {
+        return kfsAccess.kfs_getDataLocation(path, start, len);
+    }
+
+    public long getModificationTime(String path) throws IOException {
+        return kfsAccess.kfs_getModificationTime(path);
+    }
+
+    public FSDataOutputStream create(String path, short replication,
+            int bufferSize, boolean overwrite, int mode) throws IOException {
+        final boolean append = false;
+        return new FSDataOutputStream(new QFSOutputStream(
+            kfsAccess, path, replication, overwrite, append, mode), statistics);
+    }
+
+    public FSDataInputStream open(String path, int bufferSize) throws IOException {
+        return new FSDataInputStream(new QFSInputStream(kfsAccess, path,
+                                                        statistics));
+    }
+
+    public FSDataOutputStream append(String path, short replication, int bufferSize) throws IOException {
+        final boolean append    = true;
+        final boolean overwrite = false;
+        final int     mode      = 0666;
+        return new FSDataOutputStream(new QFSOutputStream(
+            kfsAccess, path, replication, overwrite, append, mode), statistics);
+    }
+
+    public void setPermission(String path, int mode)
+            throws IOException {
+        kfsAccess.kfs_retToIOException(kfsAccess.kfs_chmod(path, mode), path);
+    }
+
+    public void setOwner(String path, String username, String groupname)
+            throws IOException {
+        kfsAccess.kfs_retToIOException(kfsAccess.kfs_chown(path, username, groupname), path);
+    }
+}
diff --git a/src/core/org/apache/hadoop/fs/qfs/QFSInputStream.java b/src/core/org/apache/hadoop/fs/qfs/QFSInputStream.java
new file mode 100644
index 0000000..4da47e2
--- /dev/null
+++ b/src/core/org/apache/hadoop/fs/qfs/QFSInputStream.java
@@ -0,0 +1,106 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * @author: Sriram Rao (Kosmix Corp.)
+ *
+ * Implements the Hadoop FSInputStream interfaces to allow applications to read
+ * files in Quantcast File System (QFS), an extension of KFS.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+import java.nio.ByteBuffer;
+
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FSInputStream;
+
+import com.quantcast.qfs.access.KfsAccess;
+import com.quantcast.qfs.access.KfsInputChannel;
+
+class QFSInputStream extends FSInputStream {
+
+    private final KfsInputChannel kfsChannel;
+    private FileSystem.Statistics statistics;
+    private final long fsize;
+
+    public QFSInputStream(KfsAccess kfsAccess, String path,
+                          FileSystem.Statistics stats) throws IOException {
+        this.statistics = stats;
+        this.kfsChannel = kfsAccess.kfs_open(path);
+        if (kfsChannel == null) {
+            throw new IOException("QFS internal error -- null channel");
+        }
+        this.fsize = kfsAccess.kfs_filesize(path);
+    }
+
+    public long getPos() throws IOException {
+        if (kfsChannel == null) {
+            throw new IOException("File closed");
+        }
+        return kfsChannel.tell();
+    }
+
+    public synchronized int available() throws IOException {
+        return (int) (this.fsize - getPos());
+    }
+
+    public synchronized void seek(long targetPos) throws IOException {
+        kfsChannel.seek(targetPos);
+    }
+
+    public synchronized boolean seekToNewSource(long targetPos) throws IOException {
+        return false;
+    }
+
+    public synchronized int read() throws IOException {
+        byte b[] = new byte[1];
+        int res = read(b, 0, 1);
+        if (res == 1) {
+          if (statistics != null) {
+            statistics.incrementBytesRead(1);
+          }
+          return ((int) (b[0] & 0xff));
+        }
+        return -1;
+    }
+
+    public synchronized int read(byte b[], int off, int len) throws IOException {
+        final int res = kfsChannel.read(ByteBuffer.wrap(b, off, len));
+        // Use -1 to signify EOF
+        if (res == 0) {
+            return -1;
+        }
+        if (statistics != null) {
+          statistics.incrementBytesRead(res);
+        }
+        return res;
+    }
+
+    public synchronized void close() throws IOException {
+        kfsChannel.close();
+    }
+
+    public boolean markSupported() {
+        return false;
+    }
+
+    public void mark(int readLimit) {
+        // Do nothing
+    }
+
+    public void reset() throws IOException {
+        throw new IOException("Mark not supported");
+    }
+}
diff --git a/src/core/org/apache/hadoop/fs/qfs/QFSOutputStream.java b/src/core/org/apache/hadoop/fs/qfs/QFSOutputStream.java
new file mode 100644
index 0000000..62dc7f0
--- /dev/null
+++ b/src/core/org/apache/hadoop/fs/qfs/QFSOutputStream.java
@@ -0,0 +1,78 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * @author: Sriram Rao (Kosmix Corp.)
+ *
+ * Implements the Hadoop FSOutputStream interfaces to allow applications to write to
+ * files in Quantcast File System (QFS), an extension of KFS.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+import java.net.*;
+import java.util.*;
+import java.nio.ByteBuffer;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.util.Progressable;
+
+import com.quantcast.qfs.access.KfsAccess;
+import com.quantcast.qfs.access.KfsOutputChannel;
+
+class QFSOutputStream extends OutputStream {
+
+    private final KfsOutputChannel kfsChannel;
+
+    public QFSOutputStream(KfsAccess kfsAccess, String path,
+            short replication, boolean overwrite, boolean append, int mode) throws IOException {
+        if (append) {
+            this.kfsChannel = kfsAccess.kfs_append_ex(path, (int)replication, mode);
+        } else {
+            final long    bufferSize    = -1;
+            final long    readAheadSize = -1;
+            final boolean exclusive     = ! overwrite;
+            this.kfsChannel = kfsAccess.kfs_create_ex(
+                path, replication, exclusive, bufferSize, readAheadSize, mode);
+        }
+        if (kfsChannel == null) {
+            throw new IOException("QFS internal error -- null channel");
+        }
+    }
+
+    public long getPos() throws IOException {
+        return kfsChannel.tell();
+    }
+
+    public void write(int v) throws IOException {
+        byte[] b = new byte[1];
+        b[0] = (byte) v;
+        write(b, 0, 1);
+    }
+
+    public void write(byte b[], int off, int len) throws IOException {
+        kfsChannel.write(ByteBuffer.wrap(b, off, len));
+    }
+
+    public void flush() throws IOException {
+        kfsChannel.sync();
+    }
+
+    public synchronized void close() throws IOException {
+        flush();
+        kfsChannel.close();
+    }
+}
diff --git a/src/core/org/apache/hadoop/fs/qfs/QuantcastFileSystem.java b/src/core/org/apache/hadoop/fs/qfs/QuantcastFileSystem.java
new file mode 100644
index 0000000..182e673
--- /dev/null
+++ b/src/core/org/apache/hadoop/fs/qfs/QuantcastFileSystem.java
@@ -0,0 +1,314 @@
+/**
+ *
+ * Licensed under the Apache License, Version 2.0
+ * (the "License"); you may not use this file except in compliance with
+ * the License. You may obtain a copy of the License at
+ *
+ * http://www.apache.org/licenses/LICENSE-2.0
+ *
+ * Unless required by applicable law or agreed to in writing, software
+ * distributed under the License is distributed on an "AS IS" BASIS,
+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
+ * implied. See the License for the specific language governing
+ * permissions and limitations under the License.
+ *
+ * @author: Sriram Rao (Kosmix Corp.)
+ * 
+ * Implements the Hadoop FS interfaces to allow applications to store files in
+ * Quantcast File System (QFS). This is an extension of KFS.
+ */
+
+package org.apache.hadoop.fs.qfs;
+
+import java.io.*;
+import java.net.*;
+
+import org.apache.hadoop.conf.Configuration;
+import org.apache.hadoop.fs.FSDataInputStream;
+import org.apache.hadoop.fs.FSDataOutputStream;
+import org.apache.hadoop.fs.FileSystem;
+import org.apache.hadoop.fs.FileStatus;
+import org.apache.hadoop.fs.FileUtil;
+import org.apache.hadoop.fs.Path;
+import org.apache.hadoop.fs.ContentSummary;
+import org.apache.hadoop.fs.permission.FsPermission;
+import org.apache.hadoop.util.Progressable;
+import org.apache.hadoop.fs.BlockLocation;
+
+import com.quantcast.qfs.access.KfsFileAttr;
+
+public class QuantcastFileSystem extends FileSystem {
+
+    private FileSystem localFs;
+    private IFSImpl qfsImpl = null;
+    private URI uri;
+    private Path workingDir = new Path("/");
+
+    public QuantcastFileSystem() {
+
+    }
+
+    QuantcastFileSystem(IFSImpl fsimpl) {
+        this.qfsImpl = fsimpl;
+    }
+
+    public URI getUri() {
+        return uri;
+    }
+
+    public void initialize(URI uri, Configuration conf) throws IOException {
+      super.initialize(uri, conf);
+      try {
+        if (qfsImpl == null) {
+          if (uri.getHost() == null) {
+            qfsImpl = new QFSImpl(conf.get("fs.qfs.metaServerHost", ""),
+                                  conf.getInt("fs.qfs.metaServerPort", -1),
+                                  statistics);
+          } else {
+            qfsImpl = new QFSImpl(uri.getHost(), uri.getPort(), statistics);
+          }
+        }
+
+        this.localFs = FileSystem.getLocal(conf);
+        this.uri = URI.create(uri.getScheme() + "://" + uri.getAuthority());
+        this.workingDir = new Path("/user", System.getProperty("user.name")
+                                   ).makeQualified(this);
+        setConf(conf);
+
+      } catch (Exception e) {
+        e.printStackTrace();
+        System.out.println("Unable to initialize QFS");
+        System.exit(-1);
+      }
+    }
+
+    public Path getWorkingDirectory() {
+        return workingDir;
+    }
+
+    public void setWorkingDirectory(Path dir) {
+        workingDir = makeAbsolute(dir);
+    }
+
+    private Path makeAbsolute(Path path) {
+        if (path.isAbsolute()) {
+            return path;
+        }
+        return new Path(workingDir, path);
+    }
+
+    public boolean mkdirs(Path path, FsPermission permission
+        ) throws IOException {
+        return qfsImpl.mkdirs(makeAbsolute(path).toUri().getPath(),
+            permission.toShort()) == 0;
+    }
+
+    public FileStatus[] listStatus(Path path) throws IOException {
+        final Path absolute = makeAbsolute(path);
+        final FileStatus fs = qfsImpl.stat(absolute);
+        return fs.isDir() ?
+            qfsImpl.readdirplus(absolute) :
+            new FileStatus[] { fs };
+    }
+
+    public FileStatus getFileStatus(Path path) throws IOException {
+        return qfsImpl.stat(makeAbsolute(path));
+    }
+
+    public FSDataOutputStream append(Path path, int bufferSize,
+            Progressable progress) throws IOException {
+        return qfsImpl.append(
+            makeAbsolute(path).toUri().getPath(), (short)-1, bufferSize);
+    }
+
+    public FSDataOutputStream create(Path file, FsPermission permission,
+                                     boolean overwrite, int bufferSize,
+                                     short replication, long blockSize, Progressable progress)
+        throws IOException {
+        Path parent = file.getParent();
+        if (parent != null && !mkdirs(parent)) {
+            throw new IOException("Mkdirs failed to create " + parent);
+        }
+        return qfsImpl.create(makeAbsolute(file).toUri().getPath(),
+            replication, bufferSize, overwrite, permission.toShort());
+    }
+
+    public FSDataInputStream open(Path path, int bufferSize) throws IOException {
+        return qfsImpl.open(makeAbsolute(path).toUri().getPath(), bufferSize);
+    }
+
+    public boolean rename(Path src, Path dst) throws IOException {
+        Path absoluteS = makeAbsolute(src);
+        String srepS = absoluteS.toUri().getPath();
+        Path absoluteD = makeAbsolute(dst);
+        String srepD = absoluteD.toUri().getPath();
+
+        // System.out.println("Calling rename on: " + srepS + " -> " + srepD);
+
+        return qfsImpl.rename(srepS, srepD) == 0;
+    }
+
+    // recursively delete the directory and its contents
+    public boolean delete(Path path, boolean recursive) throws IOException {
+      Path absolute = makeAbsolute(path);
+      String srep = absolute.toUri().getPath();
+      if (qfsImpl.isFile(srep))
+        return qfsImpl.remove(srep) == 0;
+
+      FileStatus[] dirEntries = listStatus(absolute);
+      if ((!recursive) && (dirEntries != null) && 
+            (dirEntries.length != 0)) {
+        throw new IOException("Directory " + path.toString() + 
+        " is not empty.");
+      }
+      if (dirEntries != null) {
+        for (int i = 0; i < dirEntries.length; i++) {
+          delete(new Path(absolute, dirEntries[i].getPath()), recursive);
+        }
+      }
+      return qfsImpl.rmdir(srep) == 0;
+    }
+    
+    @Deprecated
+    public boolean delete(Path path) throws IOException {
+      return delete(path, true);
+    }
+
+    public short getDefaultReplication() {
+        return 3;
+    }
+
+    public boolean setReplication(Path path, short replication)
+        throws IOException {
+
+        Path absolute = makeAbsolute(path);
+        String srep = absolute.toUri().getPath();
+
+        int res = qfsImpl.setReplication(srep, replication);
+        return res >= 0;
+    }
+
+    // 64MB is the QFS block size
+
+    public long getDefaultBlockSize() {
+        return 1 << 26;
+    }
+
+    /**
+     * Return null if the file doesn't exist; otherwise, get the
+     * locations of the various chunks of the file file from QFS.
+     */
+    @Override
+    public BlockLocation[] getFileBlockLocations(FileStatus file, long start,
+        long len) throws IOException {
+
+      if (file == null) {
+        return null;
+      }
+      String srep = makeAbsolute(file.getPath()).toUri().getPath();
+      String[][] hints = qfsImpl.getDataLocation(srep, start, len);
+      if (hints == null) {
+        return null;
+      }
+      BlockLocation[] result = new BlockLocation[hints.length];
+      long blockSize = getDefaultBlockSize();
+      long length = len;
+      long blockStart = start;
+      for(int i=0; i < result.length; ++i) {
+        result[i] = new BlockLocation(null, hints[i], blockStart, 
+                                      length < blockSize ? length : blockSize);
+        blockStart += blockSize;
+        length -= blockSize;
+      }
+      return result;
+    }
+
+    public void copyFromLocalFile(boolean delSrc, Path src, Path dst) throws IOException {
+        FileUtil.copy(localFs, src, this, dst, delSrc, getConf());
+    }
+
+    public void copyToLocalFile(boolean delSrc, Path src, Path dst) throws IOException {
+        FileUtil.copy(this, src, localFs, dst, delSrc, getConf());
+    }
+
+    public Path startLocalOutput(Path fsOutputFile, Path tmpLocalFile)
+        throws IOException {
+        return tmpLocalFile;
+    }
+
+    public void completeLocalOutput(Path fsOutputFile, Path tmpLocalFile)
+        throws IOException {
+        moveFromLocalFile(tmpLocalFile, fsOutputFile);
+    }
+
+    public void setPermission(Path path, FsPermission permission) throws IOException {
+        qfsImpl.setPermission(makeAbsolute(path).toUri().getPath(),
+            permission.toShort());
+    }
+
+    public void setOwner(Path path, String username, String groupname) throws IOException {
+        qfsImpl.setOwner(makeAbsolute(path).toUri().getPath(),
+            username, groupname);
+    }
+
+    // The following is to get du and dus working without implementing file
+    // and directory counts on in the meta server.
+    private class ContentSummaryProxy extends ContentSummary
+    {
+        private ContentSummary cs;
+        private final Path path;
+
+        private ContentSummaryProxy(Path path, long len) {
+            super(len, -1, -1);
+            this.path = path;
+        }
+
+        private ContentSummary get() {
+            if (cs == null) {
+                try {
+                    cs = getContentSummarySuper(path);
+                } catch (IOException ex) {
+                    cs = this;
+                }
+            }
+            return cs; 
+        }
+
+        public long getDirectoryCount() {
+            return get().getDirectoryCount();
+        }
+
+        public long getFileCount() {
+            return get().getFileCount();
+        }
+
+        public void write(DataOutput out) throws IOException {
+            get().write(out);
+        }
+
+        public String toString(boolean qOption) {
+            return get().toString(qOption);
+        }
+    }
+
+    private ContentSummary getContentSummarySuper(Path path) throws IOException {
+        return super.getContentSummary(path);
+    }
+
+    public ContentSummary getContentSummary(Path path) throws IOException {
+        // since QFS stores sizes at each level of the dir tree, we can just stat the dir
+        final Path        absolute = makeAbsolute(path);
+        final KfsFileAttr stat     = qfsImpl.fullStat(absolute);
+        if (stat.isDirectory) {
+            final long len = stat.filesize;
+            if (len < 0) {
+                return getContentSummarySuper(absolute);
+            }
+            if (stat.dirCount < 0) {
+                return new ContentSummaryProxy(absolute, len);
+            }
+            return new ContentSummary(len, stat.fileCount, stat.dirCount + 1);
+        }
+        return new ContentSummary(stat.filesize, 1, 0);
+    }
+}
diff --git a/src/core/org/apache/hadoop/fs/qfs/package.html b/src/core/org/apache/hadoop/fs/qfs/package.html
new file mode 100644
index 0000000..d293a01
--- /dev/null
+++ b/src/core/org/apache/hadoop/fs/qfs/package.html
@@ -0,0 +1,98 @@
+<html>
+
+<!--
+   Licensed to the Apache Software Foundation (ASF) under one or more
+   contributor license agreements.  See the NOTICE file distributed with
+   this work for additional information regarding copyright ownership.
+   The ASF licenses this file to You under the Apache License, Version 2.0
+   (the "License"); you may not use this file except in compliance with
+   the License.  You may obtain a copy of the License at
+
+       http://www.apache.org/licenses/LICENSE-2.0
+
+   Unless required by applicable law or agreed to in writing, software
+   distributed under the License is distributed on an "AS IS" BASIS,
+   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
+   See the License for the specific language governing permissions and
+   limitations under the License.
+-->
+
+<head></head>
+<body>
+<h1>A client for the Quantcast filesystem (QFS)</h1>
+
+<h3>Introduction</h3>
+
+This pages describes how to use Quantcast Filesystem
+(<a href="https://github.com/quantcast/qfs"> QFS </a>) as a backing
+store with Hadoop. QFS is derived from the Kosmos File System (KFS).
+This page assumes that you have downloaded the QFS software and
+installed necessary binaries as outlined in the QFS documentation.
+
+<h3>Steps</h3>
+
+        <ul>
+          <li>In the Hadoop conf directory edit core-site.xml,
+          add the following:
+            <pre>
+&lt;property&gt;
+  &lt;name&gt;fs.qfs.impl&lt;/name&gt;
+  &lt;value&gt;org.apache.hadoop.fs.qfs.QuantcastFileSystem&lt;/value&gt;
+  &lt;description&gt;The FileSystem for qfs: uris.&lt;/description&gt;
+&lt;/property&gt;
+            </pre>
+
+          <li>In the Hadoop conf directory edit core-site.xml,
+          adding the following (with appropriate values for
+          &lt;server&gt; and &lt;port&gt;):
+            <pre>
+&lt;property&gt;
+  &lt;name&gt;fs.default.name&lt;/name&gt;
+  &lt;value&gt;qfs://&lt;server:port&gt;&lt;/value&gt;
+&lt;/property&gt;
+
+&lt;property&gt;
+  &lt;name&gt;fs.qfs.metaServerHost&lt;/name&gt;
+  &lt;value&gt;&lt;server&gt;&lt;/value&gt;
+  &lt;description&gt;The location of the QFS meta server.&lt;/description&gt;
+&lt;/property&gt;
+
+&lt;property&gt;
+  &lt;name&gt;fs.qfs.metaServerPort&lt;/name&gt;
+  &lt;value&gt;&lt;port&gt;&lt;/value&gt;
+  &lt;description&gt;The location of the meta server's port.&lt;/description&gt;
+&lt;/property&gt;
+
+</pre>
+          </li>
+
+          <li>Copy QFS's <i> kfs-&lt;version&gt;.jar </i> to Hadoop's lib directory.  This step
+          enables Hadoop's to load the QFS specific modules.  Note
+          that, kfs-&lt;version&gt;.jar was built when you compiled QFS source
+          code.  This jar file contains code that calls QFS's client
+          library code via JNI; the native code is in QFS's <i>
+          libkfs_client.so </i> library.
+          </li>
+
+          <li> When the Hadoop map/reduce trackers start up, those
+processes (on local as well as remote nodes) will now need to load
+QFS's <i> libkfs_client.so </i> library.  To simplify this process, it is advisable to
+store libkfs_client.so in an NFS accessible directory (similar to where
+Hadoop binaries/scripts are stored); then, modify Hadoop's
+conf/hadoop-env.sh adding the following line and providing suitable
+value for &lt;path&gt;:
+<pre>
+export LD_LIBRARY_PATH=&lt;path&gt;
+</pre>
+
+
+          <li>Start only the map/reduce trackers
+          <br />
+          example: execute Hadoop's bin/start-mapred.sh</li>
+        </ul>
+<br/>
+
+If the map/reduce job trackers start up, all file-I/O is done to QFS.
+
+</body>
+</html>
